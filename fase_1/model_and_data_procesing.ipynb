{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5OERGZ6kndjSkJikTrTR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelnh17/Proyecto-Sustituto/blob/main/fase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Competencia Titanic con TensorFlow Decision Forests\n",
        "\n",
        "#Este cuaderno te guiará a través de los pasos necesarios para entrenar un modelo base de Gradient Boosted Trees usando TensorFlow Decision Forests y crear una presentación para la competencia Titanic.\n",
        "\n",
        "#Este cuaderno muestra:\n",
        "\n",
        "#1. Cómo realizar un procesamiento básico de datos. Por ejemplo, se tokenizarán los nombres de los pasajeros y se dividirán los nombres de los tickets en partes.\n",
        "#2. Cómo entrenar un modelo de Gradient Boosted Trees (GBT) con parámetros predeterminados.\n",
        "#3. Cómo entrenar un GBT con parámetros predeterminados mejorados.\n",
        "#4. Cómo ajustar los parámetros de un GBT.\n",
        "#5. Cómo entrenar y combinar muchos GBTs.\n",
        "\n",
        "#Codigo copiado de\n",
        "\n",
        "#Gusthema (Owner)\n",
        "\n",
        "#achoum (Editor)\n"
      ],
      "metadata": {
        "id": "BgqIN9pfy2iF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW5GFamZyQQp",
        "outputId": "20026339-7e65-497e-a23a-82ae31c5f173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando titanic, 34877 bytes comprimidos\n",
            "\r[==================================================] 34877 bytes descargados\n",
            "Descargado y descomprimido: titanic\n",
            "Importación de fuentes de datos completada.\n"
          ]
        }
      ],
      "source": [
        "# Importa las librerías necesarias para manejar archivos, descargar y extraer datos\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile  # Para crear archivos temporales\n",
        "from urllib.request import urlopen  # Para descargar archivos desde una URL\n",
        "from urllib.parse import unquote, urlparse  # Para manejar URLs\n",
        "from urllib.error import HTTPError  # Para manejar errores HTTP\n",
        "from zipfile import ZipFile  # Para manejar archivos ZIP\n",
        "import tarfile  # Para manejar archivos TAR\n",
        "import shutil  # Para eliminar directorios\n",
        "\n",
        "# Constante que define el tamaño de los fragmentos de descarga\n",
        "CHUNK_SIZE = 40960  # Tamaño del fragmento que se descarga en cada iteración (40 KB)\n",
        "# Mapeo de la fuente de datos del Titanic, contiene la URL de descarga codificada\n",
        "DATA_SOURCE_MAPPING = 'titanic:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3136%2F26502%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240908%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240908T222413Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db7bf4cf8ca0e5bff88fe0a1f81b5c9e726e6aeceebd9d79c210062cc4e63faeec513a70ff1fe94c755078806ae9518e41f121cfedb051c8698d94fa2f30961fef7b2d00919643020416e2ab88a503bfa0bf5e25740fc05b13fc06294ce3ce3735801b56ebce0836536a4a8abd5b54fd8ef7ec0702b8bc7dbd14fbc1f7612296a6043c6f959780fff4a0fd53e7e6c8c98c7d15d1d1c94f5abe953bee4a9f1dd583d8cf8e9ce3c88afdd062f904c44638dee54590ed21c4a4d2bed31b7aa0164c051511ae35c9be615b3ab61962c6b741affb52fa23e787d9a42ff48a3c17dbd990085dd9f1c9df632b3294edf99232b651842fe445878d03af38b777cbb733472'\n",
        "\n",
        "# Definir rutas para los directorios de trabajo y entrada\n",
        "KAGGLE_INPUT_PATH = '/kaggle/input'  # Ruta donde se colocarán los datos de entrada\n",
        "KAGGLE_WORKING_PATH = '/kaggle/working'  # Ruta de trabajo para archivos temporales y resultados\n",
        "KAGGLE_SYMLINK = 'kaggle'  # Nombre del enlace simbólico que se crea para facilitar el acceso\n",
        "\n",
        "# Limpiar y preparar los directorios de trabajo\n",
        "!umount /kaggle/input/ 2> /dev/null  # Desmonta el directorio de entrada si está montado\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)  # Elimina el directorio de entrada si existe\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)  # Crea el directorio de entrada con permisos\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)  # Crea el directorio de trabajo con permisos\n",
        "\n",
        "# Crear enlaces simbólicos para los directorios de entrada y trabajo si no existen\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass  # Ignora el error si el enlace ya existe\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass  # Ignora el error si el enlace ya existe\n",
        "\n",
        "# Procesar la fuente de datos, descargar y extraer los archivos\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')  # Divide el mapeo en directorio y URL codificada\n",
        "    download_url = unquote(download_url_encoded)  # Decodifica la URL\n",
        "    filename = urlparse(download_url).path  # Extrae el nombre del archivo de la URL\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)  # Ruta donde se guardará el archivo descomprimido\n",
        "\n",
        "    try:\n",
        "        # Descargar el archivo y guardarlo temporalmente\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']  # Obtiene el tamaño total del archivo\n",
        "            print(f'Descargando {directory}, {total_length} bytes comprimidos')  # Imprime el tamaño del archivo\n",
        "\n",
        "            # Descargar el archivo en fragmentos\n",
        "            dl = 0  # Inicializa el contador de bytes descargados\n",
        "            data = fileres.read(CHUNK_SIZE)  # Lee el primer fragmento\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)  # Suma la cantidad de bytes descargados\n",
        "                tfile.write(data)  # Escribe el fragmento en el archivo temporal\n",
        "                done = int(50 * dl / int(total_length))  # Calcula el progreso de la descarga\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes descargados\")  # Imprime el progreso\n",
        "                sys.stdout.flush()  # Asegura que se imprima en tiempo real\n",
        "                data = fileres.read(CHUNK_SIZE)  # Lee el siguiente fragmento\n",
        "\n",
        "            # Descomprimir el archivo según su formato (ZIP o TAR)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)  # Extrae el archivo ZIP\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)  # Extrae el archivo TAR\n",
        "\n",
        "            print(f'\\nDescargado y descomprimido: {directory}')  # Imprime mensaje de éxito\n",
        "    except HTTPError as e:\n",
        "        # Manejo de errores HTTP (como URL expiradas)\n",
        "        print(f'Error al cargar (posiblemente caducado) {download_url} en la ruta {destination_path}')\n",
        "        continue  # Continúa con la siguiente URL\n",
        "    except OSError as e:\n",
        "        # Manejo de otros errores de archivos\n",
        "        print(f'Error al cargar {download_url} en la ruta {destination_path}')\n",
        "        continue  # Continúa con la siguiente URL\n",
        "\n",
        "print('Importación de fuentes de datos completada.')  # Imprime mensaje final de éxito\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala la librería TensorFlow Decision Forests.\n",
        "# Esta librería permite trabajar con modelos de aprendizaje automático basados en árboles de decisión.\n",
        "!pip install tensorflow_decision_forests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjMtcUFBy3po",
        "outputId": "45da07a5-a3ea-4c1f-cf76-69e43512b93f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.1.4)\n",
            "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.44.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tf-keras~=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
            "Collecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (71.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.1.2)\n",
            "Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ydf, wurlitzer, tensorflow_decision_forests\n",
            "Successfully installed tensorflow_decision_forests-1.10.0 wurlitzer-3.1.1 ydf-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importar las dependencias\n"
      ],
      "metadata": {
        "id": "X8Ej2YI-0XFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa la librería NumPy para realizar operaciones matemáticas y manipulación de matrices\n",
        "import numpy as np\n",
        "\n",
        "# Importa la librería pandas para el manejo y análisis de estructuras de datos (DataFrames)\n",
        "import pandas as pd\n",
        "\n",
        "# Importa la librería os para interactuar con el sistema operativo, como acceder a directorios y archivos\n",
        "import os\n",
        "\n",
        "# Importa la librería TensorFlow, que es utilizada para construir y entrenar modelos de Machine Learning\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importa TensorFlow Decision Forests, una librería especializada en modelos basados en bosques aleatorios y árboles de decisión\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "# Imprime la versión de TensorFlow Decision Forests instalada, para asegurar que se está utilizando la correcta\n",
        "print(f\"Se encontró TF-DF versión {tfdf.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbub-Sm4y5X_",
        "outputId": "a8f289e4-59ec-4d1d-e325-bd00ebd94059"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontró TF-DF versión 1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar el conjunto de datos\n"
      ],
      "metadata": {
        "id": "NQFKvHfI0XFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el conjunto de datos de entrenamiento del archivo CSV ubicado en la carpeta de entrada.\n",
        "# train.csv contiene los datos históricos de los pasajeros del Titanic (características y si sobrevivieron o no).\n",
        "train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
        "\n",
        "# Carga el conjunto de datos de prueba (serving_df), que no incluye la columna de \"Supervivencia\" (Survived).\n",
        "# test.csv se utiliza para hacer predicciones basadas en las características de los pasajeros.\n",
        "serving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
        "\n",
        "# Muestra las primeras 10 filas del conjunto de datos de entrenamiento para tener una vista rápida de la estructura y contenido.\n",
        "train_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a1rF63kYy7Au",
        "outputId": "baf1337a-1956-4e2c-a20e-a9c30763d2b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "5            6         0       3   \n",
              "6            7         0       1   \n",
              "7            8         0       3   \n",
              "8            9         1       3   \n",
              "9           10         1       2   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "5                                   Moran, Mr. James    male   NaN      0   \n",
              "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
              "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
              "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
              "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  \n",
              "5      0            330877   8.4583   NaN        Q  \n",
              "6      0             17463  51.8625   E46        S  \n",
              "7      1            349909  21.0750   NaN        S  \n",
              "8      2            347742  11.1333   NaN        S  \n",
              "9      0            237736  30.0708   NaN        C  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a327eb4-ddaf-4e4c-8bfe-86c63f07f24b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a327eb4-ddaf-4e4c-8bfe-86c63f07f24b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a327eb4-ddaf-4e4c-8bfe-86c63f07f24b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a327eb4-ddaf-4e4c-8bfe-86c63f07f24b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-421577ad-3375-4033-9545-062383699dd2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-421577ad-3375-4033-9545-062383699dd2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-421577ad-3375-4033-9545-062383699dd2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334042,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.6934285971809,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar el conjunto de datos\n",
        "\n",
        "Aplicaremos las siguientes transformaciones al conjunto de datos:\n",
        "\n",
        "1. Tokenizar los nombres. Por ejemplo, \"Braund, Mr. Owen Harris\" se convertirá en [\"Braund\", \"Mr.\", \"Owen\", \"Harris\"].\n",
        "2. Extraer el prefijo del ticket. Por ejemplo, el ticket \"STON/O2. 3101282\" se convertirá en \"STON/O2.\" y 3101282.\n"
      ],
      "metadata": {
        "id": "eTfj5zwIvPhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una función para preprocesar el conjunto de datos.\n",
        "def preprocess(df):\n",
        "    # Crea una copia del DataFrame para evitar modificar el original directamente.\n",
        "    df = df.copy()\n",
        "\n",
        "    # Normaliza los nombres eliminando caracteres especiales como comas, paréntesis, corchetes y comillas.\n",
        "    def normalize_name(x):\n",
        "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
        "\n",
        "    # Extrae el número de boleto, que se encuentra al final del string en la columna 'Ticket'.\n",
        "    def ticket_number(x):\n",
        "        return x.split(\" \")[-1]\n",
        "\n",
        "    # Extrae los componentes del boleto, eliminando el número (último elemento).\n",
        "    # Si no hay componentes adicionales, se asigna \"NONE\".\n",
        "    def ticket_item(x):\n",
        "        items = x.split(\" \")\n",
        "        if len(items) == 1:\n",
        "            return \"NONE\"\n",
        "        return \"_\".join(items[0:-1])\n",
        "\n",
        "    # Aplica la normalización de nombres en la columna 'Name'.\n",
        "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
        "\n",
        "    # Crea una nueva columna 'Ticket_number' con el número del boleto extraído.\n",
        "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
        "\n",
        "    # Crea una nueva columna 'Ticket_item' con el ítem del boleto (sin el número final).\n",
        "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
        "\n",
        "    # Devuelve el DataFrame preprocesado.\n",
        "    return df\n",
        "\n",
        "# Aplica la función de preprocesamiento al conjunto de datos de entrenamiento.\n",
        "preprocessed_train_df = preprocess(train_df)\n",
        "\n",
        "# Aplica la función de preprocesamiento al conjunto de datos de prueba (serving_df).\n",
        "preprocessed_serving_df = preprocess(serving_df)\n",
        "\n",
        "# Muestra las primeras 5 filas del conjunto de datos de entrenamiento preprocesado.\n",
        "preprocessed_train_df.head(5)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:30:09.50201Z",
          "iopub.execute_input": "2023-04-17T15:30:09.502467Z",
          "iopub.status.idle": "2023-04-17T15:30:09.540151Z",
          "shell.execute_reply.started": "2023-04-17T15:30:09.502432Z",
          "shell.execute_reply": "2023-04-17T15:30:09.538948Z"
        },
        "trusted": true,
        "id": "wQJ5yxTGvPhB",
        "outputId": "5f8a39a9-ccac-4db3-c6e7-9d17d2410d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                              Name     Sex   Age  SibSp  \\\n",
              "0                            Braund Mr Owen Harris    male  22.0      1   \n",
              "1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n",
              "2                             Heikkinen Miss Laina  female  26.0      0   \n",
              "3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n",
              "4                           Allen Mr William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n",
              "0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n",
              "1      0          PC 17599  71.2833   C85        C         17599          PC  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n",
              "3      0            113803  53.1000  C123        S        113803        NONE  \n",
              "4      0            373450   8.0500   NaN        S        373450        NONE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a5cb9a1-ab82-456a-b246-8c031b35a78d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Ticket_number</th>\n",
              "      <th>Ticket_item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund Mr Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>21171</td>\n",
              "      <td>A/5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>17599</td>\n",
              "      <td>PC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen Miss Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>3101282</td>\n",
              "      <td>STON/O2.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>113803</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen Mr William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>373450</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a5cb9a1-ab82-456a-b246-8c031b35a78d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a5cb9a1-ab82-456a-b246-8c031b35a78d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a5cb9a1-ab82-456a-b246-8c031b35a78d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2973517-5209-44c7-9b0b-d88b6653b5e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2973517-5209-44c7-9b0b-d88b6653b5e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2973517-5209-44c7-9b0b-d88b6653b5e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_train_df",
              "summary": "{\n  \"name\": \"preprocessed_train_df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek Master Halim Gonios William George\",\n          \"Kvillner Mr Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334042,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.6934285971809,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 679,\n        \"samples\": [\n          \"11774\",\n          \"3101277\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket_item\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"WE/P\",\n          \"A.5.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Mantenemos la lista de características de entrada del modelo. En particular, no queremos entrenar nuestro modelo con las características \"PassengerId\" y \"Ticket\".\n"
      ],
      "metadata": {
        "id": "U6NluJpmvPhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea una lista de las columnas (características) del conjunto de datos preprocesado.\n",
        "input_features = list(preprocessed_train_df.columns)\n",
        "\n",
        "# Elimina la columna 'Ticket', ya que no se utilizará directamente como característica para el modelo.\n",
        "input_features.remove(\"Ticket\")\n",
        "\n",
        "# Elimina la columna 'PassengerId', ya que es un identificador único que no aporta valor predictivo.\n",
        "input_features.remove(\"PassengerId\")\n",
        "\n",
        "# Elimina la columna 'Survived', ya que es la etiqueta objetivo (lo que queremos predecir).\n",
        "input_features.remove(\"Survived\")\n",
        "\n",
        "# La columna 'Ticket_number' podría ser eliminada si no se desea incluirla, aquí está comentada.\n",
        "# Se podría descomentar si se quiere excluirla como característica.\n",
        "# input_features.remove(\"Ticket_number\")\n",
        "\n",
        "# Imprime las características de entrada seleccionadas que serán utilizadas por el modelo.\n",
        "print(f\"Características de entrada: {input_features}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:30:14.000466Z",
          "iopub.execute_input": "2023-04-17T15:30:14.000868Z",
          "iopub.status.idle": "2023-04-17T15:30:14.00835Z",
          "shell.execute_reply.started": "2023-04-17T15:30:14.000833Z",
          "shell.execute_reply": "2023-04-17T15:30:14.006982Z"
        },
        "trusted": true,
        "id": "7ubgpSFOvPhB",
        "outputId": "6d029a2b-e9b1-495b-b7b6-6372dd733858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Características de entrada: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convertir el conjunto de datos de Pandas a un conjunto de datos de TensorFlow\n"
      ],
      "metadata": {
        "id": "ETa5Yn7BvPhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una función para dividir los nombres en tokens. TensorFlow Decision Forests (TF-DF) puede manejar tokens de texto nativamente.\n",
        "def tokenize_names(features, labels=None):\n",
        "    \"\"\"Divide los nombres en tokens. TF-DF puede consumir tokens de texto de manera nativa.\"\"\"\n",
        "    features[\"Name\"] = tf.strings.split(features[\"Name\"])  # Divide los nombres en tokens usando espacios como separadores\n",
        "    return features, labels\n",
        "\n",
        "# Convierte el DataFrame preprocesado de entrenamiento a un conjunto de datos de TensorFlow.\n",
        "# Especifica la columna 'Survived' como la etiqueta (variable objetivo) y aplica la función de tokenización.\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df, label=\"Survived\").map(tokenize_names)\n",
        "\n",
        "# Convierte el DataFrame preprocesado de prueba a un conjunto de datos de TensorFlow.\n",
        "# No se especifica una etiqueta, ya que este conjunto de datos se utiliza para hacer predicciones.\n",
        "serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:30:17.896317Z",
          "iopub.execute_input": "2023-04-17T15:30:17.896741Z",
          "iopub.status.idle": "2023-04-17T15:30:18.231195Z",
          "shell.execute_reply.started": "2023-04-17T15:30:17.896705Z",
          "shell.execute_reply": "2023-04-17T15:30:18.229792Z"
        },
        "trusted": true,
        "id": "NkP8q1ytvPhC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo con parámetros predeterminados\n",
        "\n",
        "### Entrenar el modelo\n",
        "\n",
        "Primero, entrenaremos un modelo de GradientBoostedTreesModel con los parámetros predeterminados.\n"
      ],
      "metadata": {
        "id": "MqsyxNOlvPhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define un modelo de Gradient Boosted Trees usando TensorFlow Decision Forests.\n",
        "# Configura el modelo con los siguientes parámetros:\n",
        "# - verbose=0: Muestra muy pocos logs durante el entrenamiento.\n",
        "# - features: Lista de características especificadas para el modelo (excluye cualquier característica no especificada).\n",
        "# - exclude_non_specified_features=True: Usa solo las características en la lista \"features\".\n",
        "# - random_seed=1234: Establece una semilla para garantizar la reproducibilidad de los resultados.\n",
        "model = tfdf.keras.GradientBoostedTreesModel(\n",
        "    verbose=0, # Muy pocos logs\n",
        "    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
        "    exclude_non_specified_features=True, # Usa solo las características en \"features\"\n",
        "    random_seed=1234,\n",
        ")\n",
        "\n",
        "# Entrena el modelo usando el conjunto de datos de entrenamiento.\n",
        "model.fit(train_ds)\n",
        "\n",
        "# Obtiene el inspector del modelo para evaluar el rendimiento.\n",
        "self_evaluation = model.make_inspector().evaluation()\n",
        "\n",
        "# Imprime la precisión y la pérdida del modelo en el conjunto de entrenamiento.\n",
        "# La precisión mide la exactitud de las predicciones, mientras que la pérdida evalúa el error del modelo.\n",
        "print(f\"Precisión: {self_evaluation.accuracy} Pérdida: {self_evaluation.loss}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:32:16.580089Z",
          "iopub.execute_input": "2023-04-17T15:32:16.581306Z",
          "iopub.status.idle": "2023-04-17T15:32:17.55132Z",
          "shell.execute_reply.started": "2023-04-17T15:32:16.581257Z",
          "shell.execute_reply": "2023-04-17T15:32:17.55024Z"
        },
        "trusted": true,
        "id": "xZMUZqvNvPhC",
        "outputId": "706bda59-bd85-4c6d-bb2e-d41af163d19a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 0.8260869383811951 Pérdida: 0.8608942627906799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo con parámetros predeterminados mejorados\n",
        "\n",
        "Ahora usaremos algunos parámetros específicos al crear el modelo GBT.\n"
      ],
      "metadata": {
        "id": "OCBxAxrzvPhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define un modelo de Gradient Boosted Trees usando TensorFlow Decision Forests con parámetros adicionales.\n",
        "# Configura el modelo con los siguientes parámetros:\n",
        "# - verbose=0: Muestra muy pocos logs durante el entrenamiento.\n",
        "# - features: Lista de características especificadas para el modelo (usa solo las características en \"features\").\n",
        "# - exclude_non_specified_features=True: Usa solo las características en la lista \"features\".\n",
        "# - min_examples=1: Número mínimo de ejemplos necesarios para realizar una división en el árbol.\n",
        "# - categorical_algorithm=\"RANDOM\": Algoritmo utilizado para manejar variables categóricas (aleatorio en este caso).\n",
        "# - shrinkage=0.05: Tasa de reducción del gradiente (shrinkage) para mejorar el rendimiento del modelo.\n",
        "# - split_axis=\"SPARSE_OBLIQUE\": Tipo de partición utilizada para dividir las características en árboles oblicuos dispersos.\n",
        "# - sparse_oblique_normalization=\"MIN_MAX\": Normalización aplicada a las características oblicuas dispersas.\n",
        "# - sparse_oblique_num_projections_exponent=2.0: Exponente utilizado para el número de proyecciones oblicuas dispersas.\n",
        "# - num_trees=2000: Número de árboles en el modelo.\n",
        "# - random_seed=1234: Establece una semilla para garantizar la reproducibilidad de los resultados.\n",
        "\n",
        "model = tfdf.keras.GradientBoostedTreesModel(\n",
        "    verbose=0, # Muy pocos logs\n",
        "    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
        "    exclude_non_specified_features=True, # Usa solo las características en \"features\"\n",
        "    min_examples=1,\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    shrinkage=0.05,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    sparse_oblique_normalization=\"MIN_MAX\",\n",
        "    sparse_oblique_num_projections_exponent=2.0,\n",
        "    num_trees=2000,\n",
        "    random_seed=1234,\n",
        ")\n",
        "\n",
        "# Entrena el modelo utilizando el conjunto de datos de entrenamiento.\n",
        "model.fit(train_ds)\n",
        "\n",
        "# Obtiene el inspector del modelo para evaluar su rendimiento en el conjunto de entrenamiento.\n",
        "self_evaluation = model.make_inspector().evaluation()\n",
        "\n",
        "# Imprime la precisión y la pérdida del modelo en el conjunto de entrenamiento.\n",
        "# La precisión indica la exactitud de las predicciones del modelo, mientras que la pérdida evalúa el error del modelo.\n",
        "print(f\"Precisión: {self_evaluation.accuracy} Pérdida: {self_evaluation.loss}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:06:14.822939Z",
          "iopub.execute_input": "2023-04-17T15:06:14.82343Z",
          "iopub.status.idle": "2023-04-17T15:06:16.103565Z",
          "shell.execute_reply.started": "2023-04-17T15:06:14.82339Z",
          "shell.execute_reply": "2023-04-17T15:06:16.102272Z"
        },
        "trusted": true,
        "id": "vhXaw2U_vPhC",
        "outputId": "38e225f4-7237-4907-d164-9b866f90ac0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 0.75 Pérdida: 1.0462466478347778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el modelo y también se puede observar la información sobre la importancia de las variables que el modelo ha determinado\n"
      ],
      "metadata": {
        "id": "ZtLQpR6tvPhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra un resumen del modelo de Gradient Boosted Trees.\n",
        "# El resumen proporciona información sobre la estructura del modelo, incluyendo detalles\n",
        "# sobre el número de árboles, las características utilizadas y otros parámetros del modelo.\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:06:16.104878Z",
          "iopub.execute_input": "2023-04-17T15:06:16.105239Z",
          "iopub.status.idle": "2023-04-17T15:06:16.123439Z",
          "shell.execute_reply.started": "2023-04-17T15:06:16.105206Z",
          "shell.execute_reply": "2023-04-17T15:06:16.121993Z"
        },
        "trusted": true,
        "id": "03R1fbUXvPhC",
        "outputId": "59f1338e-6999-4394-cd07-d2139bace424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"gradient_boosted_trees_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (11):\n",
            "\tAge\n",
            "\tCabin\n",
            "\tEmbarked\n",
            "\tFare\n",
            "\tName\n",
            "\tParch\n",
            "\tPclass\n",
            "\tSex\n",
            "\tSibSp\n",
            "\tTicket_item\n",
            "\tTicket_number\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.           \"Sex\"  0.805245 ################\n",
            "    2.           \"Age\"  0.372369 #####\n",
            "    3.          \"Fare\"  0.273026 ##\n",
            "    4.          \"Name\"  0.187307 \n",
            "    5.        \"Pclass\"  0.180805 \n",
            "    6.   \"Ticket_item\"  0.178416 \n",
            "    7. \"Ticket_number\"  0.178366 \n",
            "    8.         \"Parch\"  0.177684 \n",
            "    9.      \"Embarked\"  0.176070 \n",
            "   10.         \"SibSp\"  0.172557 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.  \"Sex\" 34.000000 ################\n",
            "    2. \"Name\"  2.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.           \"Age\" 428.000000 ################\n",
            "    2.          \"Fare\" 278.000000 ##########\n",
            "    3.          \"Name\" 55.000000 #\n",
            "    4.   \"Ticket_item\" 38.000000 #\n",
            "    5.           \"Sex\" 36.000000 #\n",
            "    6. \"Ticket_number\" 23.000000 \n",
            "    7.         \"Parch\" 19.000000 \n",
            "    8.        \"Pclass\" 10.000000 \n",
            "    9.      \"Embarked\"  9.000000 \n",
            "   10.         \"SibSp\"  4.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.           \"Sex\" 461.523208 ################\n",
            "    2.           \"Age\" 378.019156 #############\n",
            "    3.          \"Fare\" 275.230253 #########\n",
            "    4.          \"Name\" 118.343331 ####\n",
            "    5.        \"Pclass\" 36.228439 #\n",
            "    6.         \"Parch\" 23.516134 \n",
            "    7.   \"Ticket_item\" 21.838539 \n",
            "    8. \"Ticket_number\" 17.217955 \n",
            "    9.      \"Embarked\"  7.074696 \n",
            "   10.         \"SibSp\"  0.400482 \n",
            "\n",
            "\n",
            "\n",
            "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
            "Validation loss value: 1.04625\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 36\n",
            "Total number of nodes: 1836\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 36 Average: 51 StdDev: 4.49691\n",
            "Min: 41 Max: 61 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 41, 42)  1   2.78%   2.78% #\n",
            "[ 42, 43)  0   0.00%   2.78%\n",
            "[ 43, 44)  1   2.78%   5.56% #\n",
            "[ 44, 45)  0   0.00%   5.56%\n",
            "[ 45, 46)  3   8.33%  13.89% ###\n",
            "[ 46, 47)  0   0.00%  13.89%\n",
            "[ 47, 48)  5  13.89%  27.78% #####\n",
            "[ 48, 49)  0   0.00%  27.78%\n",
            "[ 49, 50)  3   8.33%  36.11% ###\n",
            "[ 50, 51)  0   0.00%  36.11%\n",
            "[ 51, 52) 10  27.78%  63.89% ##########\n",
            "[ 52, 53)  0   0.00%  63.89%\n",
            "[ 53, 54)  3   8.33%  72.22% ###\n",
            "[ 54, 55)  0   0.00%  72.22%\n",
            "[ 55, 56)  5  13.89%  86.11% #####\n",
            "[ 56, 57)  0   0.00%  86.11%\n",
            "[ 57, 58)  3   8.33%  94.44% ###\n",
            "[ 58, 59)  0   0.00%  94.44%\n",
            "[ 59, 60)  1   2.78%  97.22% #\n",
            "[ 60, 61]  1   2.78% 100.00% #\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 936 Average: 4.81624 StdDev: 0.493973\n",
            "Min: 3 Max: 5 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 3, 4)  44   4.70%   4.70% #\n",
            "[ 4, 5)  84   8.97%  13.68% #\n",
            "[ 5, 5] 808  86.32% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 936 Average: 30.7308 StdDev: 73.3279\n",
            "Min: 1 Max: 458 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   1,  23) 723  77.24%  77.24% ##########\n",
            "[  23,  46)  71   7.59%  84.83% #\n",
            "[  46,  69)  42   4.49%  89.32% #\n",
            "[  69,  92)  20   2.14%  91.45%\n",
            "[  92, 115)   2   0.21%  91.67%\n",
            "[ 115, 138)   7   0.75%  92.41%\n",
            "[ 138, 161)  27   2.88%  95.30%\n",
            "[ 161, 184)   8   0.85%  96.15%\n",
            "[ 184, 207)   2   0.21%  96.37%\n",
            "[ 207, 230)   4   0.43%  96.79%\n",
            "[ 230, 252)   2   0.21%  97.01%\n",
            "[ 252, 275)   0   0.00%  97.01%\n",
            "[ 275, 298)   0   0.00%  97.01%\n",
            "[ 298, 321)   1   0.11%  97.12%\n",
            "[ 321, 344)   0   0.00%  97.12%\n",
            "[ 344, 367)   5   0.53%  97.65%\n",
            "[ 367, 390)  11   1.18%  98.82%\n",
            "[ 390, 413)   4   0.43%  99.25%\n",
            "[ 413, 436)   6   0.64%  99.89%\n",
            "[ 436, 458]   1   0.11% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t428 : Age [NUMERICAL]\n",
            "\t278 : Fare [NUMERICAL]\n",
            "\t55 : Name [CATEGORICAL_SET]\n",
            "\t38 : Ticket_item [CATEGORICAL]\n",
            "\t36 : Sex [CATEGORICAL]\n",
            "\t23 : Ticket_number [CATEGORICAL]\n",
            "\t19 : Parch [NUMERICAL]\n",
            "\t10 : Pclass [NUMERICAL]\n",
            "\t9 : Embarked [CATEGORICAL]\n",
            "\t4 : SibSp [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t34 : Sex [CATEGORICAL]\n",
            "\t2 : Name [CATEGORICAL_SET]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t44 : Age [NUMERICAL]\n",
            "\t34 : Sex [CATEGORICAL]\n",
            "\t21 : Fare [NUMERICAL]\n",
            "\t5 : Pclass [NUMERICAL]\n",
            "\t2 : Name [CATEGORICAL_SET]\n",
            "\t1 : Ticket_number [CATEGORICAL]\n",
            "\t1 : Parch [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t111 : Age [NUMERICAL]\n",
            "\t75 : Fare [NUMERICAL]\n",
            "\t35 : Sex [CATEGORICAL]\n",
            "\t7 : Name [CATEGORICAL_SET]\n",
            "\t6 : Parch [NUMERICAL]\n",
            "\t5 : Pclass [NUMERICAL]\n",
            "\t5 : Embarked [CATEGORICAL]\n",
            "\t4 : Ticket_number [CATEGORICAL]\n",
            "\t4 : Ticket_item [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t239 : Age [NUMERICAL]\n",
            "\t155 : Fare [NUMERICAL]\n",
            "\t36 : Sex [CATEGORICAL]\n",
            "\t18 : Name [CATEGORICAL_SET]\n",
            "\t13 : Ticket_number [CATEGORICAL]\n",
            "\t12 : Ticket_item [CATEGORICAL]\n",
            "\t10 : Parch [NUMERICAL]\n",
            "\t6 : Pclass [NUMERICAL]\n",
            "\t6 : Embarked [CATEGORICAL]\n",
            "\t1 : SibSp [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t428 : Age [NUMERICAL]\n",
            "\t278 : Fare [NUMERICAL]\n",
            "\t55 : Name [CATEGORICAL_SET]\n",
            "\t38 : Ticket_item [CATEGORICAL]\n",
            "\t36 : Sex [CATEGORICAL]\n",
            "\t23 : Ticket_number [CATEGORICAL]\n",
            "\t19 : Parch [NUMERICAL]\n",
            "\t10 : Pclass [NUMERICAL]\n",
            "\t9 : Embarked [CATEGORICAL]\n",
            "\t4 : SibSp [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t739 : ObliqueCondition\n",
            "\t117 : ContainsBitmapCondition\n",
            "\t44 : ContainsCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t36 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t71 : ObliqueCondition\n",
            "\t37 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t197 : ObliqueCondition\n",
            "\t50 : ContainsBitmapCondition\n",
            "\t5 : ContainsCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t411 : ObliqueCondition\n",
            "\t70 : ContainsBitmapCondition\n",
            "\t15 : ContainsCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t739 : ObliqueCondition\n",
            "\t117 : ContainsBitmapCondition\n",
            "\t44 : ContainsCondition\n",
            "\n",
            "Training logs:\n",
            "Number of iteration to final model: 36\n",
            "\tIter:1 train-loss:1.267677 valid-loss:1.369485  train-accuracy:0.624531 valid-accuracy:0.543478\n",
            "\tIter:2 train-loss:1.214848 valid-loss:1.331812  train-accuracy:0.624531 valid-accuracy:0.543478\n",
            "\tIter:3 train-loss:1.164942 valid-loss:1.291869  train-accuracy:0.624531 valid-accuracy:0.543478\n",
            "\tIter:4 train-loss:1.120759 valid-loss:1.258706  train-accuracy:0.624531 valid-accuracy:0.543478\n",
            "\tIter:5 train-loss:1.079912 valid-loss:1.231839  train-accuracy:0.809762 valid-accuracy:0.717391\n",
            "\tIter:6 train-loss:1.043659 valid-loss:1.209835  train-accuracy:0.817272 valid-accuracy:0.717391\n",
            "\tIter:16 train-loss:0.793468 valid-loss:1.096304  train-accuracy:0.903630 valid-accuracy:0.739130\n",
            "\tIter:26 train-loss:0.655063 valid-loss:1.069241  train-accuracy:0.921151 valid-accuracy:0.750000\n",
            "\tIter:36 train-loss:0.562198 valid-loss:1.046247  train-accuracy:0.928661 valid-accuracy:0.750000\n",
            "\tIter:46 train-loss:0.498899 valid-loss:1.064525  train-accuracy:0.932416 valid-accuracy:0.760870\n",
            "\tIter:56 train-loss:0.455454 valid-loss:1.085791  train-accuracy:0.939925 valid-accuracy:0.750000\n",
            "\tIter:66 train-loss:0.409738 valid-loss:1.107281  train-accuracy:0.946183 valid-accuracy:0.750000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Realizar predicciones\n"
      ],
      "metadata": {
        "id": "Ai-OGpCTvPhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una función para convertir las predicciones del modelo al formato requerido por Kaggle.\n",
        "# La función toma las probabilidades de supervivencia y las convierte en una DataFrame con dos columnas:\n",
        "# - \"PassengerId\": Identificador del pasajero.\n",
        "# - \"Survived\": Resultado binario (0 o 1) basado en el umbral especificado (por defecto 0.5).\n",
        "def prediction_to_kaggle_format(model, threshold=0.5):\n",
        "    proba_survive = model.predict(serving_ds, verbose=0)[:,0]  # Predice las probabilidades de supervivencia para el conjunto de prueba\n",
        "    return pd.DataFrame({\n",
        "        \"PassengerId\": serving_df[\"PassengerId\"],  # Incluye el identificador del pasajero\n",
        "        \"Survived\": (proba_survive >= threshold).astype(int)  # Convierte las probabilidades en etiquetas binarias usando el umbral\n",
        "    })\n",
        "\n",
        "# Define una función para guardar las predicciones en un archivo CSV en el formato esperado por Kaggle.\n",
        "# La función guarda el DataFrame en la ruta especificada y muestra un mensaje confirmando la exportación.\n",
        "def make_submission(kaggle_predictions):\n",
        "    path=\"/kaggle/working/submission.csv\"  # Ruta donde se guardará el archivo CSV\n",
        "    kaggle_predictions.to_csv(path, index=False)  # Guarda el DataFrame como archivo CSV sin el índice\n",
        "    print(f\"Submission exported to {path}\")  # Muestra un mensaje con la ruta del archivo exportado\n",
        "\n",
        "# Genera las predicciones usando el modelo y las convierte al formato requerido por Kaggle.\n",
        "kaggle_predictions = prediction_to_kaggle_format(model)\n",
        "\n",
        "# Crea el archivo de envío con las predicciones en el formato adecuado y lo guarda en la ruta especificada.\n",
        "make_submission(kaggle_predictions)\n",
        "\n",
        "# Muestra las primeras líneas del archivo CSV para verificar el contenido.\n",
        "!head /kaggle/working/submission.csv\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:06:16.126575Z",
          "iopub.execute_input": "2023-04-17T15:06:16.126941Z",
          "iopub.status.idle": "2023-04-17T15:06:17.406876Z",
          "shell.execute_reply.started": "2023-04-17T15:06:16.126904Z",
          "shell.execute_reply": "2023-04-17T15:06:17.405022Z"
        },
        "trusted": true,
        "id": "xGR5E9PUvPhC",
        "outputId": "893e8547-70e6-4728-8062-03e3da7d241a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission exported to /kaggle/working/submission.csv\n",
            "PassengerId,Survived\n",
            "892,0\n",
            "893,0\n",
            "894,0\n",
            "895,0\n",
            "896,0\n",
            "897,1\n",
            "898,0\n",
            "899,0\n",
            "900,1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento de un modelo con ajuste de hiperparámetros\n",
        "\n",
        "El ajuste de hiperparámetros se activa especificando el argumento del constructor `tuner` del modelo. El objeto `tuner` contiene toda la configuración del ajuste (espacio de búsqueda, optimizador, ensayo y objetivo).\n",
        "\n"
      ],
      "metadata": {
        "id": "XItqfy1nvPhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura un proceso de búsqueda aleatoria para la optimización de hiperparámetros del modelo.\n",
        "# Utiliza la búsqueda aleatoria para explorar diferentes combinaciones de parámetros.\n",
        "\n",
        "# Define el objeto `tuner` para la búsqueda aleatoria con un número máximo de 1000 pruebas.\n",
        "tuner = tfdf.tuner.RandomSearch(num_trials=1000)\n",
        "\n",
        "# Define el espacio de búsqueda para los hiperparámetros específicos.\n",
        "# Selecciona entre diferentes valores para el número mínimo de ejemplos necesarios para realizar una división.\n",
        "tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
        "\n",
        "# Selecciona el algoritmo para manejar variables categóricas.\n",
        "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
        "\n",
        "# Configura el espacio de búsqueda para la estrategia de crecimiento de árboles.\n",
        "# Permite ajustar el máximo de profundidad para la estrategia de crecimiento LOCAL.\n",
        "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
        "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n",
        "\n",
        "# Configura el espacio de búsqueda para la estrategia de crecimiento GLOBAL.\n",
        "# Permite ajustar el número máximo de nodos para la estrategia BEST_FIRST_GLOBAL.\n",
        "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
        "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
        "\n",
        "# Opcionalmente, se puede ajustar el uso de la ganancia Hessiana.\n",
        "# tuner.choice(\"use_hessian_gain\", [True, False])\n",
        "\n",
        "# Ajusta la tasa de reducción del gradiente (shrinkage).\n",
        "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
        "\n",
        "# Ajusta el ratio de atributos candidatos para la partición de características.\n",
        "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
        "\n",
        "# Ajusta el eje de partición de características.\n",
        "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
        "\n",
        "# Configura el espacio de búsqueda para el caso de particiones oblicuas dispersas.\n",
        "# Permite ajustar la normalización, el tipo de pesos y el número de proyecciones oblicuas.\n",
        "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n",
        "oblique_space.choice(\"sparse_oblique_normalization\",\n",
        "                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n",
        "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
        "oblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n",
        "\n",
        "# Ajusta el modelo utilizando el proceso de búsqueda aleatoria definido.\n",
        "# El modelo se entrena con el conjunto de datos de entrenamiento.\n",
        "tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
        "tuned_model.fit(train_ds, verbose=0)\n",
        "\n",
        "# Evalúa el rendimiento del modelo ajustado usando el conjunto de datos de entrenamiento.\n",
        "tuned_self_evaluation = tuned_model.make_inspector().evaluation()\n",
        "\n",
        "# Imprime la precisión y la pérdida del modelo ajustado en el conjunto de entrenamiento.\n",
        "print(f\"Precisión: {tuned_self_evaluation.accuracy} Pérdida:{tuned_self_evaluation.loss}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:23:13.249675Z",
          "iopub.execute_input": "2023-04-17T15:23:13.251376Z",
          "iopub.status.idle": "2023-04-17T15:25:19.611729Z",
          "shell.execute_reply.started": "2023-04-17T15:23:13.251306Z",
          "shell.execute_reply": "2023-04-17T15:25:19.610154Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EFpsAy1vPhD",
        "outputId": "f1df1dcd-a62c-4d27-da80-5e99e41766c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpaql70hqp as temporary training directory\n",
            "Precisión: 0.8630136847496033 Pérdida:0.6749962568283081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la última línea de la celda anterior, se puede ver que la precisión es mayor que con los parámetros predeterminados y los parámetros establecidos manualmente.\n",
        "\n",
        "Esta es la idea principal detrás del ajuste de hiperparámetros.\n",
        "\n",
        "Para más información, puedes seguir este tutorial: [Ajuste automático de hiperparámetros](https://www.tensorflow.org/decision_forests/tutorials/automatic_tuning_colab)\n"
      ],
      "metadata": {
        "id": "C5-w6vjzvPhD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crear un ensamblaje\n",
        "\n",
        "Aquí se creara 100 modelos con diferentes semillas y se combinaran sus resultados.\n",
        "\n",
        "Este enfoque reduce un poco los aspectos aleatorios relacionados con la creación de modelos de aprendizaje automático.\n",
        "\n",
        "En la creación de GBT se utiliza el parámetro `honest`. Este parámetro usa diferentes ejemplos de entrenamiento para inferir la estructura y los valores de las hojas. Esta técnica de regularización intercambia ejemplos por estimaciones de sesgo.\n"
      ],
      "metadata": {
        "id": "y9KbvAlDvPhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa variables para almacenar las predicciones y contar el número de modelos entrenados.\n",
        "predictions = None\n",
        "num_predictions = 0\n",
        "\n",
        "# Realiza la evaluación con 100 modelos diferentes.\n",
        "for i in range(100):\n",
        "    print(f\"i:{i}\")  # Imprime el índice de la iteración actual\n",
        "\n",
        "    # Crea un modelo de Gradient Boosted Trees con parámetros definidos.\n",
        "    # La semilla aleatoria (random_seed) cambia en cada iteración para obtener diferentes modelos.\n",
        "    model = tfdf.keras.GradientBoostedTreesModel(\n",
        "        verbose=0,  # Muestra pocos logs durante el entrenamiento\n",
        "        features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
        "        exclude_non_specified_features=True,  # Usa solo las características especificadas en \"features\"\n",
        "        random_seed=i,  # Cambia la semilla aleatoria en cada iteración para obtener diferentes resultados\n",
        "        honest=True,  # Activa el modo honesto para una evaluación más precisa\n",
        "    )\n",
        "    # Entrena el modelo usando el conjunto de datos de entrenamiento.\n",
        "    model.fit(train_ds)\n",
        "\n",
        "    # Realiza predicciones sobre el conjunto de datos de prueba.\n",
        "    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n",
        "\n",
        "    # Agrega las predicciones actuales a las predicciones acumuladas.\n",
        "    if predictions is None:\n",
        "        predictions = sub_predictions\n",
        "    else:\n",
        "        predictions += sub_predictions\n",
        "\n",
        "    # Incrementa el contador de modelos entrenados.\n",
        "    num_predictions += 1\n",
        "\n",
        "# Calcula el promedio de las predicciones de todos los modelos.\n",
        "predictions /= num_predictions\n",
        "\n",
        "# Convierte las predicciones promedio a un DataFrame en el formato requerido por Kaggle.\n",
        "kaggle_predictions = pd.DataFrame({\n",
        "    \"PassengerId\": serving_df[\"PassengerId\"],  # Incluye el identificador del pasajero\n",
        "    \"Survived\": (predictions >= 0.5).astype(int)  # Convierte las probabilidades en etiquetas binarias usando el umbral 0.5\n",
        "})\n",
        "\n",
        "# Guarda las predicciones en un archivo CSV y muestra un mensaje con la ruta del archivo.\n",
        "make_submission(kaggle_predictions)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T15:28:37.557745Z",
          "iopub.execute_input": "2023-04-17T15:28:37.558172Z",
          "iopub.status.idle": "2023-04-17T15:28:52.809698Z",
          "shell.execute_reply.started": "2023-04-17T15:28:37.55813Z",
          "shell.execute_reply": "2023-04-17T15:28:52.808193Z"
        },
        "trusted": true,
        "id": "CUBQfqgFvPhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2cca5c-dbc7-4a50-b314-076e100cf0f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7c1079dff520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7c10881520e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7c108c555750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 8 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7c10881501f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7c108c555750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7c107a9bd5a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:3\n",
            "i:4\n",
            "i:5\n",
            "i:6\n",
            "i:7\n",
            "i:8\n",
            "i:9\n",
            "i:10\n",
            "i:11\n",
            "i:12\n",
            "i:13\n",
            "i:14\n",
            "i:15\n",
            "i:16\n",
            "i:17\n",
            "i:18\n",
            "i:19\n",
            "i:20\n",
            "i:21\n",
            "i:22\n",
            "i:23\n",
            "i:24\n",
            "i:25\n",
            "i:26\n",
            "i:27\n",
            "i:28\n",
            "i:29\n",
            "i:30\n",
            "i:31\n",
            "i:32\n",
            "i:33\n",
            "i:34\n",
            "i:35\n",
            "i:36\n",
            "i:37\n",
            "i:38\n",
            "i:39\n",
            "i:40\n",
            "i:41\n",
            "i:42\n",
            "i:43\n",
            "i:44\n",
            "i:45\n",
            "i:46\n",
            "i:47\n",
            "i:48\n",
            "i:49\n",
            "i:50\n",
            "i:51\n",
            "i:52\n",
            "i:53\n",
            "i:54\n",
            "i:55\n",
            "i:56\n",
            "i:57\n",
            "i:58\n",
            "i:59\n",
            "i:60\n",
            "i:61\n",
            "i:62\n",
            "i:63\n",
            "i:64\n",
            "i:65\n",
            "i:66\n",
            "i:67\n",
            "i:68\n",
            "i:69\n",
            "i:70\n",
            "i:71\n",
            "i:72\n",
            "i:73\n",
            "i:74\n",
            "i:75\n",
            "i:76\n",
            "i:77\n",
            "i:78\n",
            "i:79\n",
            "i:80\n",
            "i:81\n",
            "i:82\n",
            "i:83\n",
            "i:84\n",
            "i:85\n",
            "i:86\n",
            "i:87\n",
            "i:88\n",
            "i:89\n",
            "i:90\n",
            "i:91\n",
            "i:92\n",
            "i:93\n",
            "i:94\n",
            "i:95\n",
            "i:96\n",
            "i:97\n",
            "i:98\n",
            "i:99\n",
            "Submission exported to /kaggle/working/submission.csv\n"
          ]
        }
      ]
    }
  ]
}